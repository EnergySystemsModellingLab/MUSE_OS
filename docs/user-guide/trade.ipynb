{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will introduce trade between two regions. Often, there exists trade between countries, regions within countries or between regions of countries (e.g. Latin America). This could be the trading of commodities such as gas or electricity in the form of imports and exports. MUSE is able to model this trade between regions to add further realism.\n",
    "\n",
    "To keep this example straightforward we will start from the case study created in the [add a region](add-region.ipynb) tutorial. This can be downloaded [here](https://github.com/SGIModel/MUSE_OS/tree/main/docs/tutorial-code/3-add-region)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The major file changes required to implement trade occur in the `technodata` folder. Specifically, within the sector folders such as `technodata/power/` or `technodata/gas/`. In addition, we will need to create a new agent file and modify the TOML file. For this example we will only modify the `power` sector. Note that any sector can trade (apart from a preset sector), but not all sectors have to trade if you don't want them to. \n",
    "\n",
    "No changes are required for the files in the `input/` folder. We also do not need to have the same number of agents for trading, as for the sectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TradeTechnodata file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first file we must create within the `technodata/power/` folder will be the `TradeTechnodata.csv` file. This file effectively details the technodata parameters between regions. For instance, we can detail how much `R2` has to pay for `R1`'s gas or electricity in terms of `cap_par`, `fix_par` or otherwise. This also extends to other technoeconomic data, for instance `MaxCapacityGrowth` or `TotalCapacityLimit`. These inputs are the same used as in the no-trade case. The only difference being that the value refers to each of the regions.\n",
    "\n",
    "For this example, we will create a csv file with the following headers:\n",
    "\n",
    "|ProcessName|RegionName|Parameter|Unit|R1|R2|\n",
    "|-|-|-|-|-|-|\n",
    "|gasCCGT|R1|cap_par|MUSD/PJ|28.29|56.58|\n",
    "\n",
    "We can see that the technology and regions, similarly to the Technodata file are defined by the `ProcessName` and `RegionName` headers. In fact, the `TradeTechnodata.csv` follows the same naming convention as the `technodata.csv` file. The difference being that the `Parameter` column is long, as opposed to wide. Therefore, we define the parameters that we wish to assign in the rows rather than the columns. Next, we define the unit of interest in the `Unit` column followed by the regions `R1` and `R2`. \n",
    "\n",
    "As you may have noticed, we have three seperate places where we enter regions for only two total regions. This may be a bit confusing, but essentially, we have to define the costs that each region has to pay for a technology based in `RegionName`. In this example, for a gas power plant located in region `R1`, `R1` has to pay a `cap_par` of 28.29, whereas `R2` has to pay a higher fee of 56.58. This could be because of additional connection or pipeline costs.\n",
    "\n",
    "To fully populate the TradeTechnodata file we have to define the following parameters for each region and technology:\n",
    "- `cap_par`\n",
    "- `fix_par`\n",
    "- `MaxCapacityAddition`\n",
    "- `MaxCapacityGrowth`\n",
    "- `TotalCapacityLimit`\n",
    "\n",
    "We must also delete these columns from the `Technodata.csv` file, otherwise we will receive an error.\n",
    "\n",
    "To keep things simple we will just present the `cap_par` and `TotalCapacityLimit` parameters here, but in your example you should add numbers for the remaining parameters. The full case study is available at the end of this tutorial.\n",
    "\n",
    "|ProcessName|RegionName|Parameter|Unit|R1|R2|\n",
    "|-|-|-|-|-|-|\n",
    "|gasCCGT|R1|cap_par|MUSD/PJ|28.29|56.58|\n",
    "|windturbine|R1|cap_par|MUSD/PJ|43.2|0|\n",
    "|solarPV|R1|cap_par|MUSD/PJ|43.2|0|\n",
    "|gasCCGT|R2|cap_par|MUSD/PJ|57.08|28.54|\n",
    "|windturbine|R2|cap_par|MUSD/PJ|0|43.57|\n",
    "|solarPV|R2|cap_par|MUSD/PJ|0|43.57|\n",
    "|...|...|...|...|...|...|\n",
    "|gasCCGT|R1|TotalCapacityLimit|PJ/y|40000|40000|\n",
    "|windturbine|R1|TotalCapacityLimit|PJ/y|40000|40000|\n",
    "|solarPV|R1|TotalCapacityLimit|PJ/y|40000|40000|\n",
    "|gasCCGT|R2|TotalCapacityLimit|PJ/y|40000|40000|\n",
    "|windturbine|R2|TotalCapacityLimit|PJ/y|40000|40000|\n",
    "|solarPV|R2|TotalCapacityLimit|PJ/y|40000|40000|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExistingTrade file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ExistingCapacity.csv` file that was used in the non-trade cases can't specify how much existing trade there exists between regions. Therefore, the `ExistingCapacity.csv` has to be repurposed into a new input called `ExistingTrade.csv` which is able to define existing trade flows as well as existing capacity.\n",
    "\n",
    "This input is in long form, in a similar fashion to `TradeTechnodata.csv`. A quick example is shown below:\n",
    "\n",
    "|ProcessName|RegionName|Time|R1|R2|\n",
    "|-|-|-|-|-|\n",
    "|Unit|-|Year|PJ/y|PJ/y|\n",
    "|gasCCGT|R1|2010|300|0|\n",
    "|gasCCGT|R1|2020|240|0|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we have `ProcessName`, `RegionName`, `Time` and regions `R1` and `R2`. The first three follow a similar approachto the `TradeTechnodata.csv` and so the names should be consistent. The column `R1` states the existing capacity of a technology in a region in a particular year, whereas the column `R2` details the amount of existing trade that there is from `R1` to `R2` in `gasCCGT`.\n",
    "\n",
    "The amount of rows depends on the number of milestone years, technologies and regions and can get quite long. For this example, we show just the `ExistingTrade.csv` for `gasCCGT`, but you should fill out the existing trade for `windturbine` and `solarPV`. Again, we provide a link to the full files at the end of this tutorial.\n",
    "\n",
    "|ProcessName|RegionName|Time|R1|R2|\n",
    "|-|-|-|-|-|\n",
    "|Unit|-|Year|PJ/y|PJ/y|\n",
    "|gasCCGT|R1|2010|300|0|\n",
    "|gasCCGT|R1|2020|240|0|\n",
    "|gasCCGT|R2|2010|0|200|\n",
    "|gasCCGT|R2|2020|0|200|\n",
    "|gasCCGT|R1|2025|192|0|\n",
    "|gasCCGT|R2|2025|0|140|\n",
    "|gasCCGT|R1|2030|153.6|0|\n",
    "|gasCCGT|R2|2030|0|98|\n",
    "|gasCCGT|R1|2035|122.88|0|\n",
    "|gasCCGT|R2|2035|0|68.6|\n",
    "|gasCCGT|R1|2040|98.304|0|\n",
    "|gasCCGT|R2|2040|0|48.02|\n",
    "|gasCCGT|R1|2045|78.6432|0|\n",
    "|gasCCGT|R2|2045|0|33.614|\n",
    "|gasCCGT|R1|2050|62.91456|0|\n",
    "|gasCCGT|R2|2050|0|23.5298|\n",
    "|...|...|...|...|...|\n",
    "\n",
    "Once this file has been created, we can delete the original `ExistingCapacity.csv` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent file requires some changes to run successfully. The same objective metric must be used for each region and there is no need for the new and retrofit agents.\n",
    "\n",
    "We define the `AgentShare` column as `agent_share` and give them a `default` `Type`. We msut also define the objective as `ALCOE` and the `SearchRule` as `from_assets->compress->reduce_assets`. The rest of the data can stay the same as per the previous tutorials. \n",
    "\n",
    "|AgentShare|Name|RegionName|Objective1|...|SearchRule|...|Budget|Type|\n",
    "|-|-|-|-|-|-|-|-|-|\n",
    "|agent_share|A1|R1|ALCOE|...|from_assets->compress->reduce_assets|...|inf|default|\n",
    "|agent_share|A2|R1|ALCOE|...|from_assets->compress->reduce_assets|...|inf|default|\n",
    "|agent_share|A1|R2|ALCOE|...|from_assets->compress->reduce_assets|...|inf|default|\n",
    "|agent_share|A2|R2|ALCOE|...|from_assets->compress->reduce_assets|...|inf|default|\n",
    "\n",
    "\n",
    "Save the agent file for the power sector in the `technodata/power/` directory, but make sure to keep the generalised `Agents.csv` in the `technodata/` directory for the other sectors. This is as we aren't including trade in the other sectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technodata\n",
    "\n",
    "The technodata file remains largely untouched, apart from a removal of the rows which contain parameters which are defined in the `TradeTechnodata.csv` file, for example `cap_par` and `TotalCapacityLimit`. In addition, we have to amend the `AgentShare` column and replace the final `Agent2` column with the name `AgentShare` so that it matches with the `Agents.csv` file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|ProcessName|RegionName|Time|Level|cap_exp|fix_exp|var_par|var_exp|...|AgentShare|\n",
    "|-|-|-|-|-|-|-|-|-|-|\n",
    "|Unit|-|Year|-|-|-|MUS$2010/PJ|-|...|\n",
    "|gasCCGT|R1|2020|fixed|1|1|0|1|...|**0.5**|\n",
    "|gasCCGT|R1|2040|fixed|1|1|0|1|...|**0.5**|\n",
    "|...|...|...|...|...|...|...|...|...|...|\n",
    "|gasCCGT|R2|2020|fixed|1|1|0|1|...|**0.5**|\n",
    "|gasCCGT|R2|2040|fixed|1|1|0|1|...|**0.5**|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we must make a few changes in the TOML file to tell the model that we want to run trade in the model as well as the new `TradeTechnodata.csv` and `ExistingTrade.csv`\n",
    "\n",
    "We will only be making changes in the power sector in this example.\n",
    "\n",
    "The `[sectors.power]` section can stay the same. However, within the `[sectors.power.technodata]` of the TOML we need to link to the trade file, shown in the second input below:\n",
    "```\n",
    "[sectors.power.technodata]\n",
    "technodata = '{path}/technodata/power/Technodata.csv'\n",
    "trade = '{path}/technodata/power/TradeTechnodata.csv'\n",
    "commodities_in = '{path}/technodata/power/CommIn.csv'\n",
    "commodities_out = '{path}/technodata/power/CommOut.csv'\n",
    "```\n",
    "\n",
    "Next, we have to edit the section heading from `[sectors.power.subsectors.retro_and_new]` to `[sectors.power.subsectors.trade]` to define that we want to include trade. Secondly, we need to link to the new agents file that we saved in the `technodata/power/` folder. So this just requires the addition of the `power/` directory. Then we have to change the `existing_capacity` to the new `ExistingTrade.csv` file that we created. Finally, we have to link the new agents file. We must ensure that we use the `scipy` solver for this. The changes required can be seen below:\n",
    "```\n",
    "[sectors.power.subsectors.trade]\n",
    "agents = '{path}/technodata/power/Agents.csv'\n",
    "existing_capacity = '{path}/technodata/power/ExistingTrade.csv'\n",
    "lpsolver = \"scipy\"\n",
    "demand_share = \"unmet_forecasted_demand\"\n",
    "```\n",
    "\n",
    "We must also ensure that the agents' objectives are consistent across agents' regions. The scipy solver optimises trade flows amongst the agents in each region, therefore, they need to use the same objective. \n",
    "\n",
    "We can then run the model, as before, with:\n",
    "```\n",
    "python -m muse settings.toml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can visualise the results in a similar fashion to before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../tutorial-code/8-trade/building/Results/MCACapacity.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9fd8c3e2a339>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcapacity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../tutorial-code/8-trade/building/Results/MCACapacity.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    702\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../tutorial-code/8-trade/building/Results/MCACapacity.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "capacity = pd.read_csv(\"../tutorial-code/8-trade/building/Results/MCACapacity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity_grouped = capacity.groupby([\"dst_region\", \"sector\", \"technology\", \"year\"]).sum().reset_index()\n",
    "\n",
    "for region, data in capacity_grouped[capacity_grouped.sector==\"power\"].groupby(\"dst_region\"):\n",
    "    print(\"Region = {}\".format(region))\n",
    "    sns.lineplot(data=data, x=\"year\", y=\"capacity\", hue=\"technology\")\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that region `R1` has prioritised `solarPV` and `windturbine`, whereas region `R2` have prioritised `windturbine`. This is highly dependent on the costs of the various technologies in the different regions.\n",
    "\n",
    "## End of tutorials\n",
    "That brings us to the end of the tutorial. The full finished files can be found at [here](https://github.com/SGIModel/MUSE_OS/tree/main/docs/tutorial-code/8-trade/final_trade)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
